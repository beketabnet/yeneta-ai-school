# Yeneta AI School - LLM Implementation Analysis & Recommendations

## Executive Summary

**Current State**: âŒ NO REAL LLM INTEGRATION - All AI endpoints return mock responses

**Recommended Action**: Implement Multi-LLM architecture with 3-tier strategy

---

## 1. Current Implementation Status

### Backend (`ai_tools/views.py`)
- âŒ All 9 AI endpoints use mock responses
- âŒ No LLM libraries installed
- âŒ No API key management
- âŒ No routing logic

### Frontend (`services/geminiService.ts`)
- âš ï¸ Deprecated service (commented as moved to backend)
- âŒ Only placeholder API key
- âŒ No actual implementation

### Environment Configuration
- âŒ No `.env` file in backend
- âŒ Hardcoded credentials in `settings.py`
- âŒ Missing all LLM API keys

### Dependencies
**Missing Critical Libraries**:
```
openai
google-generativeai
ollama
python-dotenv
langchain
tiktoken
chromadb
```

---

## 2. KIRA-Ethiopia Research Alignment

### Required 3-Tier LLM Strategy

| Tier | Technology | Use Case | Cost | Status |
|------|-----------|----------|------|--------|
| **Tier 1** | Ollama (Gemma 2, LLaVA) | Student tutoring, offline support | FREE | âŒ Not implemented |
| **Tier 2** | Gemini (Flash/Pro) | Teacher tools, lesson planning | FREE/SUBSIDIZED | âŒ Not implemented |
| **Tier 3** | OpenAI (GPT-4o) | Premium content generation | PAID | âŒ Not implemented |

### Critical Features Needed
1. **LLM Router** - Intelligent model selection
2. **Offline Support** - Ollama for 9M out-of-school children
3. **RAG System** - Curriculum-grounded responses
4. **Cost Optimization** - Budget management & tracking

---

## 3. Recommended Implementation

### Phase 1: Foundation (Week 1-2) ğŸ”´ CRITICAL

**1.1 Create Environment Configuration**
```bash
# .env file structure
OPENAI_API_KEY=sk-...
GEMINI_API_KEY=AIza...
OLLAMA_BASE_URL=http://localhost:11434
SERP_API_KEY=...
SECRET_KEY=...
```

**1.2 Install Dependencies**
```bash
pip install openai google-generativeai ollama python-dotenv
pip install langchain tiktoken chromadb
```

**1.3 Create LLM Service Module**
- `llm_service.py` - Unified LLM client
- `llm_router.py` - Intelligent routing
- `cost_tracker.py` - Budget management

### Phase 2: Replace Mock Endpoints (Week 3-4) ğŸ”´ CRITICAL

Update all 9 AI endpoints with real LLM calls:
1. `/api/ai-tools/tutor/`
2. `/api/ai-tools/lesson-planner/`
3. `/api/ai-tools/student-insights/`
4. `/api/ai-tools/generate-rubric/`
5. `/api/ai-tools/grade-submission/`
6. `/api/ai-tools/check-authenticity/`
7. `/api/ai-tools/evaluate-practice-answer/`
8. `/api/ai-tools/summarize-conversation/`
9. `/api/ai-tools/analyze-alert/`

### Phase 3: RAG System (Week 5-6) ğŸ”´ CRITICAL

**3.1 Vector Database Setup**
- Install ChromaDB
- Process Ethiopian curriculum documents
- Create embeddings for all subjects (KG-12)
- Implement semantic search

**3.2 Benefits**
- 60-80% reduction in prompt tokens
- Eliminates hallucinations
- Curriculum-accurate responses

### Phase 4: Ollama Integration (Week 7-8) ğŸ”´ CRITICAL

**4.1 Local Model Setup**
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Download models
ollama pull gemma2:2b
ollama pull gemma2:9b
ollama pull llava:7b
```

**4.2 Offline Mode**
- Automatic fallback when offline
- Zero API cost
- Critical for rural/crisis areas

### Phase 5: Cost Optimization (Week 9-10) ğŸŸ¡ HIGH

**5.1 Budget Management**
```python
BUDGET_CONFIG = {
    'total_monthly': 500.00,  # $500/month
    'per_student_daily': 0.10,
    'per_teacher_daily': 1.00,
}
```

**5.2 Token Optimization**
- Implement token counting
- Add response caching
- Batch similar requests
- Smart prompt engineering

---

## 4. LLM Router Logic

```python
def route_request(task, user_role, complexity, connectivity):
    # Offline â†’ Always Ollama
    if connectivity == 'offline':
        return 'ollama-gemma2'
    
    # Student tutoring â†’ Ollama (free)
    if user_role == 'student' and complexity == 'basic':
        return 'ollama-gemma2'
    
    # Teacher tools â†’ Gemini (subsidized)
    if user_role == 'teacher':
        return 'gemini-pro'
    
    # Premium features â†’ OpenAI
    if task == 'content_generation':
        return 'gpt-4o'
    
    # Default â†’ Gemini Flash
    return 'gemini-flash'
```

---

## 5. Cost Analysis

### Without Multi-LLM Strategy
- All requests to GPT-4o: **$150-300/day**
- Monthly cost: **$4,500-9,000**
- âŒ Unsustainable for Ethiopian context

### With Multi-LLM Strategy
- 70% requests â†’ Ollama (FREE)
- 25% requests â†’ Gemini (FREE/subsidized)
- 5% requests â†’ OpenAI ($15-30/day)
- Monthly cost: **$450-900**
- âœ… **83-90% cost reduction**

---

## 6. Priority Action Items

### Immediate (This Week)
1. âœ… Create `.env` file with all API keys
2. âœ… Install required Python packages
3. âœ… Create `llm_service.py` module
4. âœ… Update one endpoint (tutor) as proof of concept

### Short-term (Next 2 Weeks)
5. âœ… Implement LLM router
6. âœ… Replace all 9 mock endpoints
7. âœ… Add cost tracking
8. âœ… Set up Ollama server

### Medium-term (Next 4-6 Weeks)
9. âœ… Implement RAG system
10. âœ… Process curriculum documents
11. âœ… Add offline mode
12. âœ… Build admin cost dashboard

---

## 7. Recommended File Structure

```
yeneta_backend/
â”œâ”€â”€ ai_tools/
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py      # Multi-LLM client
â”‚   â”‚   â”œâ”€â”€ llm_router.py       # Intelligent routing
â”‚   â”‚   â”œâ”€â”€ cost_tracker.py     # Budget management
â”‚   â”‚   â”œâ”€â”€ token_counter.py    # Token counting
â”‚   â”‚   â””â”€â”€ models.py           # Cost tracking models
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_engine.py       # RAG implementation
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # Vector DB interface
â”‚   â”‚   â””â”€â”€ embeddings.py       # Embedding generation
â”‚   â”œâ”€â”€ views.py                # Updated with real LLM calls
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ .env                        # Environment variables
â””â”€â”€ requirements.txt            # Updated dependencies
```

---

## 8. Success Metrics

### Technical Metrics
- âœ… 100% of AI endpoints using real LLMs
- âœ… 70%+ requests routed to free tier (Ollama)
- âœ… <500ms average response time
- âœ… 99.9% uptime with offline fallback

### Cost Metrics
- âœ… <$1,000/month total LLM costs
- âœ… <$0.10 per student per day
- âœ… 80%+ cost reduction vs single-LLM approach

### Quality Metrics
- âœ… 95%+ curriculum accuracy (via RAG)
- âœ… <5% hallucination rate
- âœ… User satisfaction >4.5/5

---

## 9. Risk Mitigation

| Risk | Mitigation Strategy |
|------|-------------------|
| API key exposure | Use environment variables, never commit to git |
| High costs | Implement budget limits, alerts at 80% threshold |
| Offline access | Ollama fallback, local model deployment |
| Poor quality | RAG system, curriculum grounding, quality checks |
| Vendor lock-in | Multi-LLM architecture, easy provider switching |

---

## 10. Next Steps

**Immediate Actions Required**:

1. **Create `.env` file** with all API keys
2. **Install dependencies**: `pip install -r requirements.txt`
3. **Set up Ollama server** for offline support
4. **Implement LLM service module**
5. **Update one endpoint** as proof of concept
6. **Test and validate** before full rollout

**Timeline**: 12 weeks to full implementation

**Budget**: $500-1,000/month operational cost

**Impact**: Enable real AI features for 9M+ students in Ethiopia
