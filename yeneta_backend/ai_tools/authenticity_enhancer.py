import logging
import json
import re
from typing import Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)

class AuthenticityEnhancer:
    """
    Enhancer for AI detection and authenticity checking.
    Uses LLM analysis to detect AI-generated patterns, repetition, and lack of personal depth.
    """
    
    @classmethod
    def analyze_text_authenticity(cls, text: str, student_grade: str = None, subject: str = None) -> str:
        """
        Build a prompt to analyze text for AI generation patterns.
        """
        prompt = f"""You are an expert AI Detection Analyst. Your task is to analyze the following text and determine if it was likely written by a human student or generated by an AI.

CONTEXT:
- Student Grade Level: {student_grade if student_grade else 'Unknown'}
- Subject: {subject if subject else 'General'}
- Text Length: {len(text.split())} words

TEXT TO ANALYZE:
\"\"\"
{text[:4000]}
\"\"\"
{(f'... (remaining {len(text) - 4000} chars truncated)' if len(text) > 4000 else '')}

ANALYSIS CRITERIA:
1. **Perplexity & Burstiness**: Does the text have the uniform, predictable flow of AI, or the varied sentence structures of a human?
2. **Personal Depth**: Does it contain personal anecdotes, specific local context (Ethiopian), or emotional nuance that AI often lacks?
3. **Repetition**: Does it repeat phrases or structures in a robotic way?
4. **Errors**: Does it have "too perfect" grammar (AI) or natural student errors (Human)?
5. **Hallucinations**: Does it contain vague or generic claims without specific evidence?

MULTILINGUAL HANDLING:
- If the text is in a non-English language (e.g., Amharic, Oromo, Tigrinya):
  1. Identify the language in your analysis.
  2. Analyze for AI patterns relative to that language (e.g., unnatural formality or "translated" feel).
  3. If you are less confident in detections for this language, default to a HIGHER 'originality_score' (give the student the benefit of the doubt) and LOWER 'confidence_score'.
  4. Explicitly mention the detected language in 'analysis_summary'.
  5. Do NOT flag text as AI solely because it uses non-English script/characters.

REQUIRED OUTPUT FORMAT:
You must return ONLY valid JSON with this exact structure:
{{
    "originality_score": 85,  // 0-100 (100 = Definitely Human, 0 = Definitely AI)
    "ai_likelihood": "Low",   // Low, Medium, High, Very High
    "confidence_score": 90,   // 0-100 (How confident are you in this assessment?)
    "flagged_sections": [
        {{
            "text": "Section of text that looks suspicious...",
            "reason": "Why this looks AI-generated (e.g., 'Generic phrasing', 'Repetitive structure')"
        }}
    ],
    "analysis_summary": "Brief explanation of why you think this is Human or AI (2-3 sentences)."
}}

IMPORTANT:
- Be fair. Do not flag generic academic writing as AI unless it shows clear signs.
- If the text is very short (< 50 words), give a lower confidence score.
- RETURN ONLY VALID JSON.
"""
        return prompt

    @classmethod
    def validate_authenticity_result(cls, result: Dict) -> Dict:
        """
        Validate and sanitize the authenticity result.
        """
        # Ensure defaults
        if not isinstance(result, dict):
            return cls._get_fallback_result()
            
        # Clamp scores
        result['originality_score'] = max(0, min(100, result.get('originality_score', 50)))
        result['confidence_score'] = max(0, min(100, result.get('confidence_score', 50)))
        
        # Ensure valid likelihood
        valid_likelihoods = ['Low', 'Medium', 'High', 'Very High']
        if result.get('ai_likelihood') not in valid_likelihoods:
            # Infer from originality score
            score = result['originality_score']
            if score > 80: result['ai_likelihood'] = 'Low'
            elif score > 60: result['ai_likelihood'] = 'Medium'
            elif score > 40: result['ai_likelihood'] = 'High'
            else: result['ai_likelihood'] = 'Very High'
            
        # Ensure flagged sections is a list
        if 'flagged_sections' not in result or not isinstance(result['flagged_sections'], list):
            result['flagged_sections'] = []
            
        return result

    @classmethod
    def _get_fallback_result(cls) -> Dict:
        return {
            "originality_score": 50,
            "ai_likelihood": "Medium",
            "confidence_score": 0,
            "flagged_sections": [],
            "analysis_summary": "Analysis failed to produce a structured result."
        }
